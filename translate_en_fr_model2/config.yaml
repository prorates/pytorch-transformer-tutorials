N: 3
alt_model: model2
batch_size: 8
d_ff: 1024
d_model: 256
datasource: translate
dropout: 0.1
experiment_name: runs/tmodel
h: 4
lang_src: en
lang_tgt: fr
lr: 0.0001
model_basename: tmodel_
num_epochs: 23
preload: latest
seq_len: 80
tokenizer_file: tokenizer_{0}
